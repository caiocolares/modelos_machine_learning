{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Treinamento do Modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/vendas.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='dtvenda').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['vlvendido', 'day_of_week', 'month', 'day_of_year', 'year'])['qtd'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8968, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - Método de Treinamento: Divisão Treino/Teste ou Validação Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows_size = 30\n",
      "train_size = 8608\n",
      "val_size = 0\n",
      "test_size = 360\n",
      "features = ['vlvendido', 'day_of_week', 'month', 'day_of_year', 'year', 'qtd']\n"
     ]
    }
   ],
   "source": [
    "windows_size = 30 # ref. day  -- 30/60\n",
    "train_size = None # ref. day\n",
    "val_size = 0 # ref. day\n",
    "test_size = 360 # ref. day\n",
    "\n",
    "flag_stationary = False\n",
    "\n",
    "features = ['vlvendido', 'day_of_week', 'month', 'day_of_year', 'year', 'qtd']\n",
    "\n",
    "if train_size is None:\n",
    "    train_size = len(df) - val_size - test_size\n",
    "\n",
    "print(f'windows_size = {windows_size}')\n",
    "print(f'train_size = {train_size}')\n",
    "print(f'val_size = {val_size}')\n",
    "print(f'test_size = {test_size}')\n",
    "print(f'features = {features}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, windows_size):\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(df) - windows_size):\n",
    "        \n",
    "        pos_target = i + windows_size\n",
    "        target = df.iloc[pos_target]['qtd']\n",
    "        \n",
    "        sample = []\n",
    "        for f in features:\n",
    "            if f == 'qtd':\n",
    "                sample += list(df.iloc[i:pos_target][f].values)\n",
    "            else:\n",
    "                sample += [df.iloc[pos_target][f]]\n",
    "        \n",
    "        X.append(sample)\n",
    "        y.append(target)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8938, 35), (8938,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = create_dataset(df, windows_size=windows_size)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.70036653,  1.02747012,  0.63342565, ..., -0.12379816,\n",
       "         0.09734602, -0.56613595],\n",
       "       [-1.70036653,  1.02747012,  0.91210052, ...,  0.09737073,\n",
       "        -0.56616088, -0.56613595],\n",
       "       [-1.70036653,  1.02747012,  0.91210052, ..., -0.56613595,\n",
       "        -0.56616088, -0.56613595],\n",
       "       ...,\n",
       "       [ 7.66896929,  0.39407968, -0.20259893, ..., -0.34496706,\n",
       "         0.53968395, -0.12379816],\n",
       "       [ 8.29609183,  0.39407968, -1.59597324, ...,  0.53970852,\n",
       "        -0.12382295,  0.09737073],\n",
       "       [11.42128724,  0.39407968, -0.48127379, ..., -0.12379816,\n",
       "         0.09734602, -0.12379816]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8578, 35), (8578,), (360, 35), (360,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = X_scaled[-test_size:, :], y[-test_size:]\n",
    "X_train, y_train = X_scaled[-test_size-val_size-train_size:-test_size-val_size, :], y[-test_size-val_size-train_size:-test_size-val_size]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 2., ..., 4., 3., 3.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - Pelo menos dois Modelos: Linear, Árvore, Ensemble, KNN, etc.\n",
    "\n",
    "Os modelos utilizados serão:\n",
    "- LinearRegression\n",
    "- DecisionTreeRegressor\n",
    "- AdaBoostRegressor\n",
    "- RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_linear_regression():\n",
    "    return LinearRegression()\n",
    "\n",
    "def get_model_decision_tree(max_depth=5, max_leaf_nodes=5):\n",
    "    return DecisionTreeRegressor(max_depth=max_depth, max_leaf_nodes=max_leaf_nodes, random_state=42)\n",
    "\n",
    "def get_model_adaboost(n_estimators=50, learning_rate=0.5, loss='linear'):\n",
    "    return AdaBoostRegressor(n_estimators=n_estimators, learning_rate=learning_rate, loss=loss, random_state=42)\n",
    "\n",
    "def get_model_random_forest(n_estimators=50,max_depth=5):\n",
    "    return RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample, model):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    test_info = X_test[:, windows_size:]\n",
    "    \n",
    "    sample_to_predict = [sample.copy()]\n",
    "\n",
    "    for i in range(test_size):\n",
    "\n",
    "        sample_to_predict = sample_to_predict[0]\n",
    "\n",
    "        if i > 0:\n",
    "            sales = list(sample_to_predict[1:windows_size]) + [y]\n",
    "            others = list(test_info[i])\n",
    "            \n",
    "            sample_to_predict = sales + others\n",
    "\n",
    "        sample_to_predict = np.array([sample_to_predict])\n",
    "        y = model.predict(sample_to_predict)[0]\n",
    "        \n",
    "        predictions.append(y)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_summary(model_name, hp, y_pred, y_test):\n",
    "    mae = mean_absolute_error(y_pred, y_test)\n",
    "    mse = mean_squared_error(y_pred, y_test)\n",
    "    rmse = root_mean_squared_error(y_pred, y_test)\n",
    "    return {\"model_name\": model_name, \"hyper_parameters\": hp,\n",
    "            \"mae\": mae, \"mse\": mse, \"rmse\": rmse}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_linear_regression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = predict(X_test[0,:], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_result = result_summary(\"linear_regression\", {}, y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 - Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_params = [\n",
    "    {\"max_depth\": 5, \"max_leaf_nodes\": 5},\n",
    "    {\"max_depth\": 3, \"max_leaf_nodes\": 10},\n",
    "    {\"max_depth\": 10, \"max_leaf_nodes\": 5},\n",
    "    {\"max_depth\": 10, \"max_leaf_nodes\": 10},\n",
    "    {\"max_depth\": 10, \"max_leaf_nodes\": 3}\n",
    "]\n",
    "\n",
    "adaboost_params = [\n",
    "    {\"n_estimators\": 50, \"learning_rate\": 0.5, \"loss\": \"linear\"},\n",
    "    {\"n_estimators\": 100, \"learning_rate\": 0.5, \"loss\": \"linear\"},\n",
    "    {\"n_estimators\": 50, \"learning_rate\": 0.1, \"loss\": \"linear\"},\n",
    "    {\"n_estimators\": 100, \"learning_rate\": 0.1, \"loss\": \"linear\"}\n",
    "]\n",
    "\n",
    "random_forest_params = [\n",
    "    {\"n_estimators\": 50, \"max_depth\": 5},\n",
    "    {\"n_estimators\": 100, \"max_depth\": 5},\n",
    "    {\"n_estimators\": 50, \"max_depth\": 10},\n",
    "    {\"n_estimators\": 100, \"max_depth\": 10}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 - Treinamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = [lr_result]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 - Arvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in decision_tree_params:\n",
    "    model = get_model_decision_tree(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = predict(X_test[0,:], model)\n",
    "    rs = result_summary(\"decision_tree\", param, y_pred, y_test)\n",
    "    resultados.append(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 - Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in adaboost_params:\n",
    "    model = get_model_adaboost(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = predict(X_test[0,:], model)\n",
    "    rs = result_summary(\"adaboost\", param, y_pred, y_test)\n",
    "    resultados.append(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in random_forest_params:\n",
    "    model = get_model_random_forest(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = predict(X_test[0,:], model)\n",
    "    rs = result_summary(\"random_forest\", param, y_pred, y_test)\n",
    "    resultados.append(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 - Métricas\n",
    "\n",
    "Por se tratar de um problema de regressão, iremos utilizar as métricas:\n",
    "\n",
    "- **MAE** (Mean Absoluto Error): Erro Médio Absoluto\n",
    "- **MSE** (Mean Squared Error): Erro Quadrático Médio\n",
    "- **RMSE** (Root Mean Squared Error): Raiz do Erro Quadrático Médio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>hyper_parameters</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear_regression</td>\n",
       "      <td>{}</td>\n",
       "      <td>3.944076e+16</td>\n",
       "      <td>3.719881e+34</td>\n",
       "      <td>1.928699e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>{'max_depth': 5, 'max_leaf_nodes': 5}</td>\n",
       "      <td>1.177941e+00</td>\n",
       "      <td>3.030859e+00</td>\n",
       "      <td>1.740936e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>{'max_depth': 3, 'max_leaf_nodes': 10}</td>\n",
       "      <td>2.216907e+01</td>\n",
       "      <td>5.348432e+02</td>\n",
       "      <td>2.312668e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': 5}</td>\n",
       "      <td>1.177941e+00</td>\n",
       "      <td>3.030859e+00</td>\n",
       "      <td>1.740936e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': 10}</td>\n",
       "      <td>1.199469e+00</td>\n",
       "      <td>3.204668e+00</td>\n",
       "      <td>1.790159e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>{'max_depth': 10, 'max_leaf_nodes': 3}</td>\n",
       "      <td>1.178351e+00</td>\n",
       "      <td>3.031957e+00</td>\n",
       "      <td>1.741251e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>{'n_estimators': 50, 'learning_rate': 0.5, 'lo...</td>\n",
       "      <td>3.701527e+01</td>\n",
       "      <td>1.445046e+03</td>\n",
       "      <td>3.801376e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>{'n_estimators': 100, 'learning_rate': 0.5, 'l...</td>\n",
       "      <td>3.701527e+01</td>\n",
       "      <td>1.445046e+03</td>\n",
       "      <td>3.801376e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>{'n_estimators': 50, 'learning_rate': 0.1, 'lo...</td>\n",
       "      <td>2.462166e+01</td>\n",
       "      <td>6.574507e+02</td>\n",
       "      <td>2.564080e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>{'n_estimators': 100, 'learning_rate': 0.1, 'l...</td>\n",
       "      <td>2.186644e+01</td>\n",
       "      <td>5.074690e+02</td>\n",
       "      <td>2.252707e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 5}</td>\n",
       "      <td>1.950486e+01</td>\n",
       "      <td>4.090589e+02</td>\n",
       "      <td>2.022521e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5}</td>\n",
       "      <td>2.138434e+01</td>\n",
       "      <td>4.900571e+02</td>\n",
       "      <td>2.213723e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 10}</td>\n",
       "      <td>2.542571e+01</td>\n",
       "      <td>6.822852e+02</td>\n",
       "      <td>2.612059e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 10}</td>\n",
       "      <td>2.311646e+01</td>\n",
       "      <td>5.618151e+02</td>\n",
       "      <td>2.370264e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name                                   hyper_parameters  \\\n",
       "0   linear_regression                                                 {}   \n",
       "1       decision_tree              {'max_depth': 5, 'max_leaf_nodes': 5}   \n",
       "2       decision_tree             {'max_depth': 3, 'max_leaf_nodes': 10}   \n",
       "3       decision_tree             {'max_depth': 10, 'max_leaf_nodes': 5}   \n",
       "4       decision_tree            {'max_depth': 10, 'max_leaf_nodes': 10}   \n",
       "5       decision_tree             {'max_depth': 10, 'max_leaf_nodes': 3}   \n",
       "6            adaboost  {'n_estimators': 50, 'learning_rate': 0.5, 'lo...   \n",
       "7            adaboost  {'n_estimators': 100, 'learning_rate': 0.5, 'l...   \n",
       "8            adaboost  {'n_estimators': 50, 'learning_rate': 0.1, 'lo...   \n",
       "9            adaboost  {'n_estimators': 100, 'learning_rate': 0.1, 'l...   \n",
       "10      random_forest               {'n_estimators': 50, 'max_depth': 5}   \n",
       "11      random_forest              {'n_estimators': 100, 'max_depth': 5}   \n",
       "12      random_forest              {'n_estimators': 50, 'max_depth': 10}   \n",
       "13      random_forest             {'n_estimators': 100, 'max_depth': 10}   \n",
       "\n",
       "             mae           mse          rmse  \n",
       "0   3.944076e+16  3.719881e+34  1.928699e+17  \n",
       "1   1.177941e+00  3.030859e+00  1.740936e+00  \n",
       "2   2.216907e+01  5.348432e+02  2.312668e+01  \n",
       "3   1.177941e+00  3.030859e+00  1.740936e+00  \n",
       "4   1.199469e+00  3.204668e+00  1.790159e+00  \n",
       "5   1.178351e+00  3.031957e+00  1.741251e+00  \n",
       "6   3.701527e+01  1.445046e+03  3.801376e+01  \n",
       "7   3.701527e+01  1.445046e+03  3.801376e+01  \n",
       "8   2.462166e+01  6.574507e+02  2.564080e+01  \n",
       "9   2.186644e+01  5.074690e+02  2.252707e+01  \n",
       "10  1.950486e+01  4.090589e+02  2.022521e+01  \n",
       "11  2.138434e+01  4.900571e+02  2.213723e+01  \n",
       "12  2.542571e+01  6.822852e+02  2.612059e+01  \n",
       "13  2.311646e+01  5.618151e+02  2.370264e+01  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados.to_csv('data/resultados.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 - Comparação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
