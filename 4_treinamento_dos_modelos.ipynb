{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Treinamento do Modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/vendas.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='dtvenda').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['vlvendido', 'day_of_week', 'month', 'day_of_year', 'year'])['qtd'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8968, 6)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - Método de Treinamento: Divisão Treino/Teste ou Validação Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows_size = 30\n",
      "train_size = 8608\n",
      "val_size = 0\n",
      "test_size = 360\n",
      "features = ['vlvendido', 'day_of_week', 'month', 'day_of_year', 'year', 'qtd']\n"
     ]
    }
   ],
   "source": [
    "windows_size = 30 # ref. day  -- 30/60\n",
    "train_size = None # ref. day\n",
    "val_size = 0 # ref. day\n",
    "test_size = 360 # ref. day\n",
    "\n",
    "flag_stationary = False\n",
    "\n",
    "features = ['vlvendido', 'day_of_week', 'month', 'day_of_year', 'year', 'qtd']\n",
    "\n",
    "if train_size is None:\n",
    "    train_size = len(df) - val_size - test_size\n",
    "\n",
    "print(f'windows_size = {windows_size}')\n",
    "print(f'train_size = {train_size}')\n",
    "print(f'val_size = {val_size}')\n",
    "print(f'test_size = {test_size}')\n",
    "print(f'features = {features}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, windows_size):\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(df) - windows_size):\n",
    "        \n",
    "        pos_target = i + windows_size\n",
    "        target = df.iloc[pos_target]['qtd']\n",
    "        \n",
    "        sample = []\n",
    "        for f in features:\n",
    "            if f == 'qtd':\n",
    "                sample += list(df.iloc[i:pos_target][f].values)\n",
    "            else:\n",
    "                sample += [df.iloc[pos_target][f]]\n",
    "        \n",
    "        X.append(sample)\n",
    "        y.append(target)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8938, 35), (8938,))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = create_dataset(df, windows_size=windows_size)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.70036653,  1.02747012,  0.63342565, ..., -0.12379816,\n",
       "         0.09734602, -0.56613595],\n",
       "       [-1.70036653,  1.02747012,  0.91210052, ...,  0.09737073,\n",
       "        -0.56616088, -0.56613595],\n",
       "       [-1.70036653,  1.02747012,  0.91210052, ..., -0.56613595,\n",
       "        -0.56616088, -0.56613595],\n",
       "       ...,\n",
       "       [ 7.66896929,  0.39407968, -0.20259893, ..., -0.34496706,\n",
       "         0.53968395, -0.12379816],\n",
       "       [ 8.29609183,  0.39407968, -1.59597324, ...,  0.53970852,\n",
       "        -0.12382295,  0.09737073],\n",
       "       [11.42128724,  0.39407968, -0.48127379, ..., -0.12379816,\n",
       "         0.09734602, -0.12379816]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8578, 35), (8578,), (360, 35), (360,))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = X_scaled[-test_size:, :], y[-test_size:]\n",
    "X_train, y_train = X_scaled[-test_size-val_size-train_size:-test_size-val_size, :], y[-test_size-val_size-train_size:-test_size-val_size]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 2., ..., 4., 3., 3.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - Pelo menos dois Modelos: Linear, Árvore, Ensemble, KNN, etc.\n",
    "\n",
    "Os modelos utilizados serão:\n",
    "- LinearRegression\n",
    "- DecisionTreeRegressor\n",
    "- AdaBoostRegressor\n",
    "- RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_linear_regression():\n",
    "    return LinearRegression()\n",
    "\n",
    "def get_model_decision_tree(max_depth=5, max_leaf_nodes=5):\n",
    "    return DecisionTreeRegressor(max_depth=max_depth, max_leaf_nodes=max_leaf_nodes, random_state=42)\n",
    "\n",
    "def get_model_adaboost(n_estimators=50, learning_rate=0.5, loss='linear'):\n",
    "    return AdaBoostRegressor(n_estimators=n_estimators, learning_rate=learning_rate, loss=loss, random_state=42)\n",
    "\n",
    "def get_model_random_forest(n_estimators=50,max_depth=5):\n",
    "    return RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample, model):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    test_info = X_test[:, windows_size:]\n",
    "    \n",
    "    sample_to_predict = [sample.copy()]\n",
    "\n",
    "    for i in range(test_size):\n",
    "\n",
    "        sample_to_predict = sample_to_predict[0]\n",
    "\n",
    "        if i > 0:\n",
    "            sales = list(sample_to_predict[1:windows_size]) + [y]\n",
    "            others = list(test_info[i])\n",
    "            \n",
    "            sample_to_predict = sales + others\n",
    "\n",
    "        sample_to_predict = np.array([sample_to_predict])\n",
    "        y = model.predict(sample_to_predict)[0]\n",
    "        \n",
    "        predictions.append(y)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_summary(model_name, hp, y_pred, y_test):\n",
    "    mae = mean_absolute_error(y_pred, y_test)\n",
    "    mse = mean_squared_error(y_pred, y_test)\n",
    "    rmse = root_mean_squared_error(y_pred, y_test)\n",
    "    return {\"model_name\": model_name, \"hyper_parameters\": hp,\n",
    "            \"mae\": mae, \"mse\": mse, \"rmse\": rmse}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_linear_regression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = predict(X_test[0,:], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_result = result_summary(\"linear_regression\", {}, y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 - Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_params = [\n",
    "    {\"max_depth\": 5, \"max_leaf_nodes\": 5},\n",
    "    {\"max_depth\": 3, \"max_leaf_nodes\": 10},\n",
    "    {\"max_depth\": 10, \"max_leaf_nodes\": 5},\n",
    "    {\"max_depth\": 10, \"max_leaf_nodes\": 10},\n",
    "    {\"max_depth\": 10, \"max_leaf_nodes\": 3}\n",
    "]\n",
    "\n",
    "adaboost_params = [\n",
    "    {\"n_estimators\": 50, \"learning_rate\": 0.5, \"loss\": \"linear\"},\n",
    "    {\"n_estimators\": 100, \"learning_rate\": 0.5, \"loss\": \"linear\"},\n",
    "    {\"n_estimators\": 50, \"learning_rate\": 0.1, \"loss\": \"linear\"},\n",
    "    {\"n_estimators\": 100, \"learning_rate\": 0.1, \"loss\": \"linear\"}\n",
    "]\n",
    "\n",
    "random_forest_params = [\n",
    "    {\"n_estimators\": 50, \"max_depth\": 5},\n",
    "    {\"n_estimators\": 100, \"max_depth\": 5},\n",
    "    {\"n_estimators\": 50, \"max_depth\": 10},\n",
    "    {\"n_estimators\": 100, \"max_depth\": 10}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 - Treinamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = [lr_result]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 - Arvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in decision_tree_params:\n",
    "    model = get_model_decision_tree(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = predict(X_test[0,:], model)\n",
    "    rs = result_summary(\"decision_tree\", param, y_pred, y_test)\n",
    "    resultados.append(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 - Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in adaboost_params:\n",
    "    model = get_model_adaboost(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = predict(X_test[0,:], model)\n",
    "    rs = result_summary(\"adaboost\", param, y_pred, y_test)\n",
    "    resultados.append(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in random_forest_params:\n",
    "    model = get_model_random_forest(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = predict(X_test[0,:], model)\n",
    "    rs = result_summary(\"random_forest\", param, y_pred, y_test)\n",
    "    resultados.append(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_name': 'linear_regression',\n",
       "  'hyper_parameters': {},\n",
       "  'mae': np.float64(3.9440762869143624e+16),\n",
       "  'mse': np.float64(3.7198806897977575e+34),\n",
       "  'rmse': np.float64(1.928699222221484e+17)},\n",
       " {'model_name': 'decision_tree',\n",
       "  'hyper_parameters': {'max_depth': 5, 'max_leaf_nodes': 5},\n",
       "  'mae': np.float64(1.1779409602836854),\n",
       "  'mse': np.float64(3.0308586851366126),\n",
       "  'rmse': np.float64(1.740936151941424)},\n",
       " {'model_name': 'decision_tree',\n",
       "  'hyper_parameters': {'max_depth': 3, 'max_leaf_nodes': 10},\n",
       "  'mae': np.float64(22.169067483890483),\n",
       "  'mse': np.float64(534.8431988122967),\n",
       "  'rmse': np.float64(23.126677210794824)},\n",
       " {'model_name': 'decision_tree',\n",
       "  'hyper_parameters': {'max_depth': 10, 'max_leaf_nodes': 5},\n",
       "  'mae': np.float64(1.1779409602836854),\n",
       "  'mse': np.float64(3.0308586851366126),\n",
       "  'rmse': np.float64(1.740936151941424)},\n",
       " {'model_name': 'decision_tree',\n",
       "  'hyper_parameters': {'max_depth': 10, 'max_leaf_nodes': 10},\n",
       "  'mae': np.float64(1.1994690295522168),\n",
       "  'mse': np.float64(3.2046676557442098),\n",
       "  'rmse': np.float64(1.7901585560346909)},\n",
       " {'model_name': 'decision_tree',\n",
       "  'hyper_parameters': {'max_depth': 10, 'max_leaf_nodes': 3},\n",
       "  'mae': np.float64(1.1783507123088837),\n",
       "  'mse': np.float64(3.031956649664702),\n",
       "  'rmse': np.float64(1.741251460778914)},\n",
       " {'model_name': 'adaboost',\n",
       "  'hyper_parameters': {'n_estimators': 50,\n",
       "   'learning_rate': 0.5,\n",
       "   'loss': 'linear'},\n",
       "  'mae': np.float64(37.01527081097065),\n",
       "  'mse': np.float64(1445.0461053080085),\n",
       "  'rmse': np.float64(38.013762051499306)},\n",
       " {'model_name': 'adaboost',\n",
       "  'hyper_parameters': {'n_estimators': 100,\n",
       "   'learning_rate': 0.5,\n",
       "   'loss': 'linear'},\n",
       "  'mae': np.float64(37.01527081097065),\n",
       "  'mse': np.float64(1445.0461053080085),\n",
       "  'rmse': np.float64(38.013762051499306)},\n",
       " {'model_name': 'adaboost',\n",
       "  'hyper_parameters': {'n_estimators': 50,\n",
       "   'learning_rate': 0.1,\n",
       "   'loss': 'linear'},\n",
       "  'mae': np.float64(24.621658207012995),\n",
       "  'mse': np.float64(657.4507040983011),\n",
       "  'rmse': np.float64(25.64080154945046)},\n",
       " {'model_name': 'adaboost',\n",
       "  'hyper_parameters': {'n_estimators': 100,\n",
       "   'learning_rate': 0.1,\n",
       "   'loss': 'linear'},\n",
       "  'mae': np.float64(21.866443049430867),\n",
       "  'mse': np.float64(507.46898075463224),\n",
       "  'rmse': np.float64(22.527072174488904)},\n",
       " {'model_name': 'random_forest',\n",
       "  'hyper_parameters': {'n_estimators': 50, 'max_depth': 5},\n",
       "  'mae': np.float64(19.5048579728979),\n",
       "  'mse': np.float64(409.05892100366003),\n",
       "  'rmse': np.float64(20.225205091757662)},\n",
       " {'model_name': 'random_forest',\n",
       "  'hyper_parameters': {'n_estimators': 100, 'max_depth': 5},\n",
       "  'mae': np.float64(21.384336588090886),\n",
       "  'mse': np.float64(490.05708354443567),\n",
       "  'rmse': np.float64(22.137232969466524)},\n",
       " {'model_name': 'random_forest',\n",
       "  'hyper_parameters': {'n_estimators': 50, 'max_depth': 10},\n",
       "  'mae': np.float64(25.425708718764874),\n",
       "  'mse': np.float64(682.2852432492301),\n",
       "  'rmse': np.float64(26.120590407745958)},\n",
       " {'model_name': 'random_forest',\n",
       "  'hyper_parameters': {'n_estimators': 100, 'max_depth': 10},\n",
       "  'mae': np.float64(23.116459153659807),\n",
       "  'mse': np.float64(561.8151063206421),\n",
       "  'rmse': np.float64(23.70263922690134)}]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
